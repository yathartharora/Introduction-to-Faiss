{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datasets import load_dataset\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/Users/bytedance/.cache/huggingface/datasets/embedding-data___json/embedding-data--sentence-compression-d643585deb6e0073/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"embedding-data/sentence-compression\")\n",
    "sentences = []\n",
    "for i in range(len(dataset[\"train\"])):\n",
    "    sentences.append(dataset[\"train\"][i][\"set\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Universal Sentence Encoder to generate embeddings for each sentence (You can use any other Transformer based model as well.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Sentence Encoder to create sentence embeddings\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 17:14:12.528526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype string\n",
      "\t [[{{node inputs}}]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed(sentences)\n",
    "shape = embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./sentence-embedding.pkl\",\"wb\") as out:\n",
    "    pickle.dump({'sentences': sentences, 'embeddings': embeddings}, out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required package\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "#Load the sentences and their corresponding embeddings\n",
    "sentences = []\n",
    "embeddings = []\n",
    "with open('./sentence-embedding.pkl','rb') as f:\n",
    "    pkl_embeddings = pickle.load(f)\n",
    "sentences = pkl_embeddings['sentences']\n",
    "embeddings = pkl_embeddings['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the index of dimension: shape\n",
    "index= faiss.IndexFlatL2(shape)\n",
    "index.is_trained #Output: true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)\n",
    "\n",
    "#Retrieve nearest-k results\n",
    "k = 4\n",
    "#Generate the embedding for query q\n",
    "q = embed([\"I like the game of chess.\"])\n",
    "\n",
    "D, result = index.search(q,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulgarian top chess player Veselin Topalov, having the White pieces, drew against Gata Kamsky the 1st game of the Chess Challenge match.\n",
      "A chess grandmaster took on pupils in a Bletchingley school's chess club in a sponsored game.\n",
      "Bulgarian chess player Veselin Topalov will play white in the first game of chess against Viswanathan Anand, which will take place on Saturday, April 24, FOCUS News Agency.\n",
      "Chess maestro Viswanathan Anand is CNN-IBN Indian of the Year 2012.\n"
     ]
    }
   ],
   "source": [
    "#Prints the top-k similar sentences to the query from our collection\n",
    "for item in result[0]:\n",
    "    print(sentences[item])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndexIVFFFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required package\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "#Load the sentences and their corresponding embeddings\n",
    "sentences = []\n",
    "embeddings = []\n",
    "with open('./sentence-embedding.pkl','rb') as f:\n",
    "    pkl_embeddings = pickle.load(f)\n",
    "sentences = pkl_embeddings['sentences']\n",
    "embeddings = pkl_embeddings['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.is_trainednlist = 50\n",
    "#Create the index\n",
    "quantizer = faiss.IndexFlatL2(shape)\n",
    "index = faiss.IndexIVFFlat(quantizer,shape,nlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained #Output: false\n",
    "index.train(embeddings)\n",
    "index.is_trained #Output: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve nearest-k results\n",
    "k = 4\n",
    "#Generate the embedding for query q\n",
    "q = embed([\"I like the game of chess.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, result = index.search(q,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recently decided that I wanted to make a game.\n",
      "One thing that I have realised about local football is that those at the helm of our game have not been told that football belongs to the nation.\n",
      "World in Flames is honestly one of the best games I've played in a long time.\n",
      "What's That Face is an Internet flash game for PC and notebook is a game of memory.\n"
     ]
    }
   ],
   "source": [
    "#Prints the top-k similar sentences to the query from our collection\n",
    "for item in result[0]:\n",
    "    print(sentences[item])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters\n",
    "nlist = 50\n",
    "\n",
    "#Number of chunks for each embeddging\n",
    "m = 8\n",
    "\n",
    "#initialize the faiss index using PQ\n",
    "quantizer = faiss.IndexFlatL2(shape)\n",
    "index = faiss.IndexIVFPQ(quantizer, shape, nlist, m, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained #Output: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the index on the embeddings\n",
    "index.train(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index.is_trained #Output: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recently decided that I wanted to make a game.\n",
      "``This is my last season and I just want to play -- it doesn't matter where,'' Battle said.\n",
      "You're here because you want to learn how to become a vampire in Elder Scrolls V:\n",
      "What's That Face is an Internet flash game for PC and notebook is a game of memory.\n"
     ]
    }
   ],
   "source": [
    "index.add(embeddings)\n",
    "\n",
    "k = 4\n",
    "query = embed([\"I like the game of chess.\"])\n",
    "\n",
    "D, result = index.search(query,k)\n",
    "\n",
    "#Prints the top-k similar sentences to the query from our collection\n",
    "for item in result[0]:\n",
    "    print(sentences[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
